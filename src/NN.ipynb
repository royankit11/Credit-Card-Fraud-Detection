{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c024065",
   "metadata": {},
   "source": [
    "## Neural Network for Credit Card Fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "388df0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from scipy import sparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "SAMPLE_SIZE = None # use smaller sample for testing, set to None for full dataset\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd50f2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Data Preprocessing Functions ----\n",
    "def load_data_optimized():\n",
    "    print(\"[INFO] Loading data...\")\n",
    "    transaction = pd.read_csv(\"train_transaction.csv\", usecols=lambda c: c != \"TransactionDT\")\n",
    "    identity = pd.read_csv(\"train_identity.csv\")\n",
    "    df = transaction.merge(identity, on=\"TransactionID\", how=\"left\")\n",
    "    if SAMPLE_SIZE:\n",
    "        df = df.sample(SAMPLE_SIZE, random_state=42)\n",
    "        print(f\"[INFO] Using sample of {len(df):,} rows\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess_data_optimized(df):\n",
    "    print(\"[INFO] Preprocessing data...\")\n",
    "    y = df[\"isFraud\"].astype(int)\n",
    "    X = df.drop(columns=[\"isFraud\"])\n",
    "\n",
    "    numeric_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "    categorical_cols = X.select_dtypes(exclude=[\"number\"]).columns.tolist()\n",
    "\n",
    "    # Fill missing values\n",
    "    X[numeric_cols] = X[numeric_cols].fillna(0)\n",
    "    X[categorical_cols] = X[categorical_cols].fillna(\"missing\")\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", StandardScaler(with_mean=False), numeric_cols),\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), categorical_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    print(f\"[INFO] Transformed shape: {X_transformed.shape}\")\n",
    "\n",
    "    if sparse.issparse(X_transformed):\n",
    "        X_transformed = X_transformed.toarray()\n",
    "\n",
    "    return X_transformed, y, preprocessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe01555b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FraudNet(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes=(128, 64)):\n",
    "        super().__init__()\n",
    "        h1, h2 = hidden_sizes\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, h1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h1, h2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(h2, 1)  # binary logit\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(1)  # [batch]\n",
    "\n",
    "\n",
    "def train_torch_model(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    model_name=None,\n",
    "    hidden_sizes=(128, 64),\n",
    "    num_epochs=5,\n",
    "    batch_size=1024,\n",
    "    lr=1e-3\n",
    "):\n",
    "    print(f\"[INFO] Using device: {device}\")\n",
    "    input_dim = X_train.shape[1]\n",
    "    print(f\"[INFO] Input dim: {input_dim}\")\n",
    "\n",
    "    # Ensure y are NumPy arrays\n",
    "    y_train_np = np.asarray(y_train)\n",
    "    y_test_np  = np.asarray(y_test)\n",
    "\n",
    "    # Class imbalance -> pos_weight for BCEWithLogitsLoss\n",
    "    weights = class_weight.compute_class_weight(\n",
    "        class_weight=\"balanced\",\n",
    "        classes=np.unique(y_train_np),\n",
    "        y=y_train_np\n",
    "    )\n",
    "    class_weights = dict(zip(np.unique(y_train_np), weights))\n",
    "    w0, w1 = class_weights[0], class_weights[1]\n",
    "    pos_weight = torch.tensor([w1 / w0], dtype=torch.float32, device=device)\n",
    "\n",
    "    # ----- KEY PART: cast to float32 -----\n",
    "    X_train_t = torch.from_numpy(np.asarray(X_train)).float()     # <- float32\n",
    "    y_train_t = torch.from_numpy(y_train_np.astype(np.float32))   # labels as float32 for BCE\n",
    "    X_test_t  = torch.from_numpy(np.asarray(X_test)).float()      # <- float32\n",
    "    y_test_t  = torch.from_numpy(y_test_np.astype(np.int64))      # keep ints for reporting\n",
    "\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    model = FraudNet(input_dim, hidden_sizes).to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    history = {\"epoch\": [], \"loss\": []}\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch_X)\n",
    "            loss = criterion(logits, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * batch_X.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        history[\"epoch\"].append(epoch)\n",
    "        history[\"loss\"].append(epoch_loss)\n",
    "        print(f\"[EPOCH {epoch}/{num_epochs}] loss = {epoch_loss:.4f}\")\n",
    "\n",
    "    # ---- Evaluation ----\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_t = X_test_t.to(device)\n",
    "        logits = model(X_test_t)\n",
    "        probs = torch.sigmoid(logits).cpu().numpy()\n",
    "        y_pred = (probs >= 0.5).astype(int)\n",
    "\n",
    "    print(\"\\n[METRICS]\")\n",
    "    print(classification_report(y_test_np, y_pred, digits=4))\n",
    "    roc = roc_auc_score(y_test_np, probs)\n",
    "    cm = confusion_matrix(y_test_np, y_pred)\n",
    "    print(\"ROC AUC:\", roc)\n",
    "    print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "    if model_name is not None:\n",
    "        os.makedirs(\"models\", exist_ok=True)\n",
    "        path = f\"models/{model_name}.pt\"\n",
    "        torch.save(model.state_dict(), path)\n",
    "        print(f\"[SAVED] {path}\")\n",
    "\n",
    "    return model, history, {\"roc_auc\": roc, \"confusion_matrix\": cm}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bf9aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n",
      "[INFO] Preprocessing data...\n",
      "[INFO] Transformed shape: (590540, 2863)\n",
      "(472432, 2863) (118108, 2863)\n",
      "[INFO] Using device: cpu\n",
      "[INFO] Input dim: 2863\n",
      "[EPOCH 1/5] loss = 0.9331\n",
      "[EPOCH 2/5] loss = 0.8569\n",
      "[EPOCH 3/5] loss = 0.8235\n",
      "[EPOCH 4/5] loss = 0.8086\n",
      "[EPOCH 5/5] loss = 0.7874\n",
      "\n",
      "[METRICS]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9885    0.9033    0.9440    113975\n",
      "           1     0.2104    0.7106    0.3247      4133\n",
      "\n",
      "    accuracy                         0.8966    118108\n",
      "   macro avg     0.5995    0.8070    0.6343    118108\n",
      "weighted avg     0.9613    0.8966    0.9223    118108\n",
      "\n",
      "ROC AUC: 0.8910849269467332\n",
      "Confusion Matrix:\n",
      " [[102953  11022]\n",
      " [  1196   2937]]\n",
      "[SAVED] models/torch_nn_full.pt\n"
     ]
    }
   ],
   "source": [
    "# ----- Run NN on FULL Dataset -----\n",
    "# Load + preprocess\n",
    "df = load_data_optimized()\n",
    "X_full, y_full, preproc = preprocess_data_optimized(df)\n",
    "\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(\n",
    "    X_full,\n",
    "    y_full,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_full\n",
    ")\n",
    "\n",
    "print(X_train_full.shape, X_test_full.shape)\n",
    "\n",
    "# Train model\n",
    "full_model, full_hist, full_metrics = train_torch_model(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    X_test_full,\n",
    "    y_test_full,\n",
    "    model_name=\"torch_nn_full\",\n",
    "    hidden_sizes=(128, 64),\n",
    "    num_epochs=5,        # bump to e.g. 10–20 once it’s stable\n",
    "    batch_size=1024,\n",
    "    lr=1e-3\n",
    ")\n",
    "# 5, 1024, 1e-3 gave ROC: 0.891\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2752a671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading data...\n",
      "(472432, 50) (118108, 50)\n",
      "[INFO] Using device: cpu\n",
      "[INFO] Input dim: 50\n",
      "[EPOCH 1/5] loss = 1.0331\n",
      "[EPOCH 2/5] loss = 0.9488\n",
      "[EPOCH 3/5] loss = 0.9190\n",
      "[EPOCH 4/5] loss = 0.8964\n",
      "[EPOCH 5/5] loss = 0.8803\n",
      "\n",
      "[METRICS]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9885    0.8159    0.8939    113975\n",
      "           1     0.1269    0.7380    0.2166      4133\n",
      "\n",
      "    accuracy                         0.8132    118108\n",
      "   macro avg     0.5577    0.7769    0.5552    118108\n",
      "weighted avg     0.9583    0.8132    0.8702    118108\n",
      "\n",
      "ROC AUC: 0.8622823802151611\n",
      "Confusion Matrix:\n",
      " [[92990 20985]\n",
      " [ 1083  3050]]\n",
      "[SAVED] models/torch_nn_pca.pt\n"
     ]
    }
   ],
   "source": [
    "# ----- Run NN On PCA Dataset -----\n",
    "# Load PCA features\n",
    "pca_df = pd.read_csv(\"pca_features.csv\")\n",
    "X_pca = pca_df.values.astype(np.float32)\n",
    "\n",
    "# Load labels\n",
    "df_labels = load_data_optimized()\n",
    "y_pca = df_labels[\"isFraud\"].astype(int).values\n",
    "\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
    "    X_pca,\n",
    "    y_pca,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_pca\n",
    ")\n",
    "\n",
    "print(X_train_pca.shape, X_test_pca.shape)\n",
    "\n",
    "# Train PCA model\n",
    "pca_model, pca_hist, pca_metrics = train_torch_model(\n",
    "    X_train_pca,\n",
    "    y_train_pca,\n",
    "    X_test_pca,\n",
    "    y_test_pca,\n",
    "    model_name=\"torch_nn_pca\",\n",
    "    hidden_sizes=(64, 32),\n",
    "    num_epochs=5,\n",
    "    batch_size=1024,\n",
    "    lr=1e-3\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-hw4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
